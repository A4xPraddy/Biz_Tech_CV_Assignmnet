{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH5V_gmaYj_D",
        "outputId": "28281f95-f4f7-45e9-8748-9a23447b2184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬‡ï¸ Downloading Dataset...\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "âœ… Renamed 'Gloves-and-bare-hands-detection-2' to 'dataset'.\n",
            "âœ… Step 1 Successful. Now Step 2 will work!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from roboflow import Roboflow\n",
        "\n",
        "\n",
        "if os.path.exists(\"dataset\"):\n",
        "    shutil.rmtree(\"dataset\")\n",
        "    print(\" Removed empty/broken dataset folder.\")\n",
        "\n",
        "\n",
        "base_dir = \"submission/Part_1_Glove_Detection\"\n",
        "os.makedirs(f\"{base_dir}/output\", exist_ok=True)\n",
        "os.makedirs(f\"{base_dir}/logs\", exist_ok=True)\n",
        "\n",
        "\n",
        "print(\" Downloading Dataset...\")\n",
        "\n",
        "\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"ynxqkPjvRzJuWC72JB3N\")\n",
        "project = rf.workspace(\"dolphin-nog9y\").project(\"gloves-and-bare-hands-detection\")\n",
        "version = project.version(2)\n",
        "dataset = version.download(\"yolov8\")\n",
        "\n",
        "\n",
        "found = False\n",
        "for folder in os.listdir('.'):\n",
        "    # Look for the folder Roboflow just made\n",
        "    if os.path.isdir(folder) and \"detection\" in folder and folder != \"submission\":\n",
        "        os.rename(folder, \"dataset\")\n",
        "        print(f\"Renamed '{folder}' to 'dataset'.\")\n",
        "        found = True\n",
        "        break\n",
        "\n",
        "if found:\n",
        "    print(\" Step 1 Successful. Now Step 2 will work!\")\n",
        "else:\n",
        "    print(\"Error: Dataset download failed ?\")\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "\n",
        "data_yaml = None\n",
        "for root, _, files in os.walk(\"dataset\"):\n",
        "    if \"data.yaml\" in files:\n",
        "        data_yaml = os.path.join(root, \"data.yaml\")\n",
        "        break\n",
        "\n",
        "if not data_yaml:\n",
        "    print(\"Error: data.yaml not found. \")\n",
        "else:\n",
        "\n",
        "    print(f\" Starting training using config: {data_yaml}\")\n",
        "    model = YOLO('yolov8n.pt')\n",
        "\n",
        "    model.train(\n",
        "        data=data_yaml,\n",
        "        epochs=20,\n",
        "        imgsz=640,\n",
        "        batch=16,\n",
        "        project='submission/training_logs',\n",
        "        name='glove_detection_run',\n",
        "        exist_ok=True,\n",
        "        verbose=True\n",
        "    )\n",
        "    print(\" Training Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ecypPetYyCm",
        "outputId": "5dec2ff9-6d8e-481f-a4a6-d9700faf856c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.244)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "ğŸš€ Starting training using config: dataset/data.yaml\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 106.2MB/s 0.1s\n",
            "Ultralytics 8.3.244 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=glove_detection_run, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=submission/training_logs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/submission/training_logs/glove_detection_run, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 20.7MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 105.2MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 858.0Â±417.0 MB/s, size: 23.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/train/labels... 712 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 712/712 2.5Kit/s 0.3s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 356.3Â±198.6 MB/s, size: 21.3 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/valid/labels... 139 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 139/139 1.6Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/valid/labels.cache\n",
            "Plotting labels to /content/submission/training_logs/glove_detection_run/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/submission/training_logs/glove_detection_run\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/20      2.09G      1.131      2.633      1.588         18        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 3.2it/s 14.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.1it/s 2.3s\n",
            "                   all        139        181    0.00564      0.982      0.298      0.161\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/20      2.57G      1.116      1.936      1.505         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.2it/s 10.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.3it/s 2.2s\n",
            "                   all        139        181      0.577      0.204      0.354      0.168\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/20      2.59G      1.091      1.687      1.464         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.3it/s 10.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.6it/s 1.9s\n",
            "                   all        139        181      0.238      0.513      0.254      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/20       2.6G      1.116      1.597      1.493         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.3it/s 10.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.0it/s 2.5s\n",
            "                   all        139        181      0.696      0.247      0.217     0.0913\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/20      2.62G      1.083      1.483      1.464         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.3it/s 10.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 1.9it/s 2.6s\n",
            "                   all        139        181      0.408      0.376      0.399       0.22\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/20      2.64G      1.045      1.374       1.44         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.4it/s 10.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.0it/s 2.5s\n",
            "                   all        139        181      0.552      0.423      0.427       0.22\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/20      2.66G      1.002      1.263      1.409         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.2it/s 10.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.2it/s 2.3s\n",
            "                   all        139        181      0.582      0.574      0.567      0.283\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/20      2.67G     0.9852      1.233      1.388         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.1it/s 10.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.7it/s 1.9s\n",
            "                   all        139        181      0.533      0.581      0.531      0.297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/20      2.68G      0.984      1.183      1.389         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.1it/s 11.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.8it/s 1.8s\n",
            "                   all        139        181      0.512      0.645      0.534      0.317\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/20      2.71G     0.9553      1.077      1.355         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.1it/s 10.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.6it/s 2.0s\n",
            "                   all        139        181      0.725      0.685      0.728      0.462\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/20      2.72G      0.833      1.041       1.42          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 3.4it/s 13.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.3it/s 1.5s\n",
            "                   all        139        181      0.642      0.647      0.669      0.395\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/20      2.74G      0.768     0.9303      1.335         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.2it/s 10.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.8it/s 1.8s\n",
            "                   all        139        181      0.767       0.77      0.808      0.541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/20      2.75G     0.7253     0.8558       1.29          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.2it/s 10.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.8it/s 1.8s\n",
            "                   all        139        181      0.734      0.831      0.801      0.546\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/20      2.78G     0.7089     0.7705      1.273          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.1it/s 10.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.2it/s 1.6s\n",
            "                   all        139        181      0.781      0.682      0.757      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/20      2.79G     0.6803      0.742      1.271          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.2it/s 10.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.0it/s 1.7s\n",
            "                   all        139        181      0.718      0.814      0.781      0.517\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/20      2.81G      0.661     0.6728      1.233          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 3.4it/s 13.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.8it/s 1.8s\n",
            "                   all        139        181      0.724      0.824      0.845      0.601\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/20      2.82G     0.6353     0.6414      1.215          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.2it/s 10.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.9it/s 1.7s\n",
            "                   all        139        181      0.807        0.8      0.852       0.61\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/20      2.84G     0.6147     0.5867      1.178          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.2it/s 10.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.0it/s 1.7s\n",
            "                   all        139        181      0.877       0.78      0.905      0.668\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/20      2.86G     0.5897     0.5599      1.178          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.2it/s 10.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.0it/s 1.6s\n",
            "                   all        139        181      0.879      0.788      0.901      0.674\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/20      2.88G     0.5669     0.5391      1.147         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 45/45 4.0it/s 11.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.5it/s 1.4s\n",
            "                   all        139        181      0.799      0.897      0.891      0.656\n",
            "\n",
            "20 epochs completed in 0.076 hours.\n",
            "Optimizer stripped from /content/submission/training_logs/glove_detection_run/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/submission/training_logs/glove_detection_run/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/submission/training_logs/glove_detection_run/weights/best.pt...\n",
            "Ultralytics 8.3.244 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 2.0it/s 2.5s\n",
            "                   all        139        181      0.829      0.837      0.901      0.674\n",
            "         gloverotation         40         44      0.803      0.834      0.904      0.724\n",
            "       surgical-gloves         99        137      0.856      0.839      0.898      0.624\n",
            "Speed: 0.2ms preprocess, 2.5ms inference, 0.0ms loss, 4.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/submission/training_logs/glove_detection_run\u001b[0m\n",
            "âœ… Training Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile submission/Part_1_Glove_Detection/detection_script.py\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "LABEL_MAP = {\n",
        "    \"surgical-gloves\": \"gloved_hand\",\n",
        "    \"glove\": \"gloved_hand\",\n",
        "    \"gloverotation\": \"gloved_hand\",\n",
        "    \"hand\": \"bare_hand\",\n",
        "    \"bare\": \"bare_hand\"\n",
        "}\n",
        "\n",
        "\n",
        "COLORS = {\"gloved_hand\": (0, 255, 0), \"bare_hand\": (0, 0, 255)}\n",
        "\n",
        "def normalize_label(raw_label):\n",
        "    \"\"\"Normalize dataset labels to project requirements.\"\"\"\n",
        "    if raw_label in LABEL_MAP:\n",
        "        return LABEL_MAP[raw_label]\n",
        "\n",
        "    if \"glove\" in raw_label.lower():\n",
        "        return \"gloved_hand\"\n",
        "    return \"bare_hand\"\n",
        "\n",
        "def run_inference(input_dir, output_dir, model_path, conf_thres):\n",
        "    input_path = Path(input_dir)\n",
        "    output_path = Path(output_dir)\n",
        "    logs_path = Path(\"submission/Part_1_Glove_Detection/logs\")\n",
        "\n",
        "    # Ensure directories exist\n",
        "    output_path.mkdir(parents=True, exist_ok=True)\n",
        "    logs_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(f\"Loading model: {model_path}\")\n",
        "    try:\n",
        "        model = YOLO(model_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Critical Error loading model: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Gather images\n",
        "    valid_exts = {\".jpg\", \".jpeg\", \".png\"}\n",
        "    images = [p for p in input_path.iterdir() if p.suffix.lower() in valid_exts]\n",
        "\n",
        "    if not images:\n",
        "        print(\"No images found in input directory.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Processing {len(images)} images...\")\n",
        "\n",
        "    # Run Inference (Stream mode for memory efficiency)\n",
        "    results = model.predict(\n",
        "        source=[str(p) for p in images],\n",
        "        conf=conf_thres,\n",
        "        stream=True,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    for result in tqdm(results, total=len(images)):\n",
        "        filename = os.path.basename(result.path)\n",
        "        img_out = result.orig_img.copy()\n",
        "\n",
        "        # JSON Schema\n",
        "        log_entry = {\n",
        "            \"filename\": filename,\n",
        "            \"detections\": []\n",
        "        }\n",
        "\n",
        "        for box in result.boxes:\n",
        "            # Extract Integer Coordinates\n",
        "            x1, y1, x2, y2 = [int(v) for v in box.xyxy[0].tolist()]\n",
        "            conf = float(box.conf[0])\n",
        "\n",
        "            # Resolve Class Name\n",
        "            raw_class = model.names[int(box.cls[0])]\n",
        "            label = normalize_label(raw_class)\n",
        "\n",
        "            # Update Log\n",
        "            log_entry[\"detections\"].append({\n",
        "                \"label\": label,\n",
        "                \"confidence\": round(conf, 2),\n",
        "                \"bbox\": [x1, y1, x2, y2]\n",
        "            })\n",
        "\n",
        "            # Draw Annotation\n",
        "            color = COLORS.get(label, (255, 255, 255))\n",
        "            cv2.rectangle(img_out, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "            label_text = f\"{label} {conf:.2f}\"\n",
        "            (w, h), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
        "            cv2.rectangle(img_out, (x1, y1 - 20), (x1 + w, y1), color, -1)\n",
        "            cv2.putText(\n",
        "                img_out, label_text, (x1, y1 - 5),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1\n",
        "            )\n",
        "\n",
        "        # Save Artifacts\n",
        "        cv2.imwrite(str(output_path / filename), img_out)\n",
        "\n",
        "        json_path = logs_path / f\"{Path(filename).stem}.json\"\n",
        "        with open(json_path, 'w') as f:\n",
        "            json.dump(log_entry, f, indent=4)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--input\", required=True, help=\"Input folder\")\n",
        "    parser.add_argument(\"--output\", default=\"submission/Part_1_Glove_Detection/output\")\n",
        "    parser.add_argument(\"--weights\", required=True, help=\"Path to .pt model\")\n",
        "    parser.add_argument(\"--confidence\", type=float, default=0.45)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    run_inference(args.input, args.output, args.weights, args.confidence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORUbDezDapgz",
        "outputId": "49eb74c5-9ce0-49da-fdf1-ecbc26f2c766"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing submission/Part_1_Glove_Detection/detection_script.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile submission/Part_1_Glove_Detection/README.md\n",
        "# Part 1: Glove Compliance Detection Pipeline\n",
        "\n",
        "## Project Overview\n",
        "This repository contains a computer vision solution to detect `gloved_hand` and `bare_hand` classes for safety compliance monitoring.\n",
        "\n",
        "## Technical Implementation\n",
        "*   **Model:** YOLOv8 Nano (`yolov8n`). Selected for optimal real-time performance on edge hardware.\n",
        "*   **Data Source:** Roboflow Universe (Gloves & Bare Hands).\n",
        "*   **Preprocessing:**\n",
        "    *   Applied Transfer Learning on ~800 images.\n",
        "    *   Utilized Mosaic augmentation to improve robustness.\n",
        "    *   Implemented a **Label Normalization Layer** in the inference script to handle inconsistencies in the source dataset (e.g., mapping `gloverotation` to `gloved_hand`).\n",
        "\n",
        "## Usage\n",
        "**Run the detection script:**\n",
        "```bash\n",
        "python detection_script.py \\\n",
        "  --input data/images \\\n",
        "  --output results/ \\\n",
        "  --weights best.pt \\\n",
        "  --confidence 0.45"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "znqlD3JSa9QI",
        "outputId": "2c385c5e-b19e-4ca6-b275-85186c375174"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing submission/Part_1_Glove_Detection/README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "# 1. Cleanup old outputs\n",
        "if os.path.exists(\"submission/Part_1_Glove_Detection/output\"):\n",
        "    shutil.rmtree(\"submission/Part_1_Glove_Detection/output\")\n",
        "print(\" Cleared old output.\")\n",
        "\n",
        "# 2. Find Images\n",
        "image_source = None\n",
        "for root, dirs, files in os.walk(\"dataset\"):\n",
        "    if \"valid\" in dirs and \"images\" in os.listdir(os.path.join(root, \"valid\")):\n",
        "        image_source = os.path.join(root, \"valid\", \"images\")\n",
        "        break\n",
        "    # Fallback search\n",
        "    if \"images\" in dirs:\n",
        "        temp_path = os.path.join(root, \"images\")\n",
        "        if any(f.endswith(\".jpg\") for f in os.listdir(temp_path)):\n",
        "            image_source = temp_path\n",
        "            break\n",
        "\n",
        "# 3. Execute\n",
        "if image_source:\n",
        "    print(f\" Processing images from: {image_source}\")\n",
        "    cmd = [\n",
        "        \"python\", \"submission/Part_1_Glove_Detection/detection_script.py\",\n",
        "        \"--input\", image_source,\n",
        "        \"--output\", \"submission/Part_1_Glove_Detection/output\",\n",
        "        \"--weights\", \"submission/training_logs/glove_detection_run/weights/best.pt\",\n",
        "        \"--confidence\", \"0.45\"\n",
        "    ]\n",
        "    subprocess.run(cmd, check=True)\n",
        "    print(\" Inference Complete. Outputs generated.\")\n",
        "else:\n",
        "    print(\" Error: Could not find dataset images.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bOv8Bm_mbUB0",
        "outputId": "7dd8260c-6d41-4780-a76d-de16791324ef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ§¹ Cleared old output.\n",
            "ğŸš€ Processing images from: dataset/valid/images\n",
            "âœ… Inference Complete. Outputs generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "print(\" Creating final submission zip...\")\n",
        "shutil.make_archive('submission_final', 'zip', 'submission')\n",
        "\n",
        "print(\" Downloading file...\")\n",
        "files.download('submission_final.zip')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "xw8K-v7rcZA5",
        "outputId": "31da6410-461d-42bd-eb85-2e331ef98e5b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Creating final submission zip...\n",
            " Downloading file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_64c5a65a-28d7-4d42-8ea6-08f983c64d8b\", \"submission_final.zip\", 23835440)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}